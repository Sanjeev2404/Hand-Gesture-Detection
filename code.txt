import cv2
import mediapipe as mp
import numpy as np
from google.colab import files
import matplotlib.pyplot as plt
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(static_image_mode=True,
min_detection_confidence=0.7)
mp_draw = mp.solutions.drawing_utils
def classify_gesture(landmarks):
thumb_tip = landmarks[4].y
index_tip = landmarks[8].y
middle_tip = landmarks[12].y
if index_tip < thumb_tip and middle_tip < thumb_tip:
return "✌️ Peace/Victory"
elif index_tip < thumb_tip:
return "☝️ Pointing"
else:
return "👍 Thumbs Up (default)"
uploaded = files.upload()
for fn in uploaded.keys():
EXP.NO:8 MINI PROJECT: HAND GESTURE RECOGNITION

img = cv2.imread(fn)
rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
results = hands.process(rgb)
if results.multi_hand_landmarks:
for hand_landmarks in results.multi_hand_landmarks:
mp_draw.draw_landmarks(img, hand_landmarks,
mp_hands.HAND_CONNECTIONS)
gesture = classify_gesture(hand_landmarks.landmark)
print(f"{fn} → {gesture}")
else:
print(f"{fn} → No hand detected")

plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.axis("off")
plt.show()